{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "collapsed": false
            },
            "source": [
                "# Simulations with reinforcement learning"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "collapsed": true,
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "source": [
                "In this notebook you can run simulations with 5 different reinforcement learning algorithms. There are different example buildings that can be simulated.\n",
                "\n",
                "<br>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/usr/local/lib/python3.10/dist-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
                        "  logger.warn(\n"
                    ]
                }
            ],
            "source": [
                "import sinergym\n",
                "from sinergym.utils.callbacks import LoggerEvalCallback\n",
                "from sinergym.utils.rewards import *\n",
                "from sinergym.utils.wrappers import LoggerWrapper, NormalizeObservation\n",
                "from sinergym.utils.constants import RANGES_5ZONE\n",
                "from datetime import datetime\n",
                "import gym\n",
                "from stable_baselines3 import DQN, DDPG, PPO, A2C, SAC, TD3\n",
                "\n",
                "\n",
                "from stable_baselines3.common.callbacks import CallbackList\n",
                "from stable_baselines3.common.vec_env import DummyVecEnv\n",
                "import numpy as np\n",
                "\n",
                "from math import exp\n",
                "from typing import Any, Dict, List, Tuple, Union\n",
                "from gym import Env"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Reward functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "\"\"\"Implementation of reward functions.\"\"\"\n",
                "\n",
                "\n",
                "class BaseReward(object):\n",
                "\n",
                "    def __init__(self, env):\n",
                "        \"\"\"\n",
                "        Base reward class.\n",
                "\n",
                "        All reward functions should inherit from this class.\n",
                "\n",
                "        Args:\n",
                "            env (Env): Gym environment.\n",
                "        \"\"\"\n",
                "        self.env = env\n",
                "\n",
                "    def __call__(self):\n",
                "        \"\"\"Method for calculating the reward function.\"\"\"\n",
                "        raise NotImplementedError(\n",
                "            \"Reward class must have a `__call__` method.\")\n",
                "\n",
                "\n",
                "class MyLinearReward(BaseReward):\n",
                "\n",
                "    def __init__(\n",
                "        self,\n",
                "        env: Env,\n",
                "        temperature_variable: Union[str, list],\n",
                "        energy_variable: str,\n",
                "        range_comfort_winter: Tuple[int, int],\n",
                "        range_comfort_summer: Tuple[int, int],\n",
                "        summer_start: Tuple[int, int] = (6, 1),\n",
                "        summer_final: Tuple[int, int] = (9, 30),\n",
                "        energy_weight: float = 0.6,\n",
                "        #energy_weight: float = 1,\n",
                "        lambda_energy: float = 0.003,\n",
                "        #lambda_energy: float = 1,\n",
                "        lambda_temperature: float = 50\n",
                "    ):\n",
                "        \"\"\"\n",
                "        Linear reward function.\n",
                "\n",
                "        It considers the energy consumption and the absolute difference to temperature comfort.\n",
                "\n",
                "        .. math::\n",
                "            R = - W * lambda_E * power - (1 - W) * lambda_T * (max(T - T_{low}, 0) + max(T_{up} - T, 0))\n",
                "\n",
                "        Args:\n",
                "            env (Env): Gym environment.\n",
                "            temperature_variable (Union[str, list]): Name(s) of the temperature variable(s).\n",
                "            energy_variable (str): Name of the energy/power variable.\n",
                "            range_comfort_winter (Tuple[int,int]): Temperature comfort range for cold season. Depends on environment you are using.\n",
                "            range_comfort_summer (Tuple[int,int]): Temperature comfort range for hot season. Depends on environment you are using.\n",
                "            summer_start (Tuple[int,int]): Summer session tuple with month and day start. Defaults to (6,1).\n",
                "            summer_final (Tuple[int,int]): Summer session tuple with month and day end. defaults to (9,30).\n",
                "            energy_weight (float, optional): Weight given to the energy term. Defaults to 0.5.\n",
                "            lambda_energy (float, optional): Constant for removing dimensions from power(1/W). Defaults to 1e-4.\n",
                "            lambda_temperature (float, optional): Constant for removing dimensions from temperature(1/C). Defaults to 1.0.\n",
                "        \"\"\"\n",
                "\n",
                "        super(MyLinearReward, self).__init__(env)\n",
                "\n",
                "        # Name of the variables\n",
                "        self.temp_name = temperature_variable\n",
                "        self.energy_name = energy_variable\n",
                "\n",
                "        # Reward parameters\n",
                "        self.range_comfort_winter = range_comfort_winter\n",
                "        self.range_comfort_summer = range_comfort_summer\n",
                "        self.W_energy = energy_weight\n",
                "        self.lambda_energy = lambda_energy\n",
                "        self.lambda_temp = lambda_temperature\n",
                "\n",
                "        # Summer period\n",
                "        self.summer_start = summer_start  # (month,day)\n",
                "        self.summer_final = summer_final  # (month,day)\n",
                "\n",
                "    def __call__(self) -> Tuple[float, Dict[str, Any]]:\n",
                "        \"\"\"\n",
                "        Calculate the reward function.\n",
                "\n",
                "        Returns:\n",
                "            Tuple[float, Dict[str, Any]]: Reward value and dictionary with their individual components.\n",
                "        \"\"\"\n",
                "        # Current observation\n",
                "        obs_dict = self.env.obs_dict.copy()\n",
                "\n",
                "        # Energy term\n",
                "        #reward_energy = - self.lambda_energy * obs_dict[self.energy_name]\n",
                "        reward_energy = - (self.lambda_energy * obs_dict[self.energy_name])\n",
                "\n",
                "        # Comfort\n",
                "        comfort, temps = self._get_comfort(obs_dict)\n",
                "\n",
                "        if comfort == 0:\n",
                "            reward_comfort = 5\n",
                "        else:\n",
                "            reward_comfort = - self.lambda_temp * comfort\n",
                "        # Weighted sum of both terms\n",
                "        reward = self.W_energy * reward_energy + \\\n",
                "            (1.0 - self.W_energy) * reward_comfort\n",
                "\n",
                "        reward_terms = {\n",
                "            'reward_energy': reward_energy,\n",
                "            'total_energy': obs_dict[self.energy_name],\n",
                "            'reward_comfort': reward_comfort,\n",
                "            'abs_comfort': comfort,\n",
                "            'temperatures': temps\n",
                "        }\n",
                "\n",
                "        return reward, reward_terms\n",
                "\n",
                "    def _get_comfort(self,\n",
                "                     obs_dict: Dict[str,\n",
                "                                    Any]) -> Tuple[float,\n",
                "                                                   List[float]]:\n",
                "        \"\"\"Calculate the comfort term of the reward.\n",
                "\n",
                "        Returns:\n",
                "            Tuple[float, List[float]]: comfort penalty and List with temperatures used.\n",
                "        \"\"\"\n",
                "\n",
                "        hour = obs_dict[\"hour\"]\n",
                "        month = obs_dict['month']\n",
                "        day = obs_dict['day']\n",
                "        year = obs_dict['year']\n",
                "        current_dt = datetime(year, month, day)\n",
                "\n",
                "        # Periods\n",
                "        summer_start_date = datetime(\n",
                "            year,\n",
                "            self.summer_start[0],\n",
                "            self.summer_start[1])\n",
                "        summer_final_date = datetime(\n",
                "            year,\n",
                "            self.summer_final[0],\n",
                "            self.summer_final[1])\n",
                "\n",
                "\n",
                "\n",
                "        if current_dt >= summer_start_date and current_dt <= summer_final_date:\n",
                "            if current_dt.weekday() >= 5 or hour not in range(8,19):\n",
                "                temp_range = (15,30)\n",
                "            else:\n",
                "                temp_range = self.range_comfort_summer \n",
                "        else:\n",
                "            if current_dt.weekday() >= 5 or hour not in range(8,19):\n",
                "                temp_range = (15,30)\n",
                "            else:\n",
                "                temp_range = self.range_comfort_winter\n",
                "\n",
                "\n",
                "        temps = [v for k, v in obs_dict.items() if k in self.temp_name]\n",
                "        comfort = 0.0\n",
                "        for T in temps:\n",
                "            if T < temp_range[0] or T > temp_range[1]:\n",
                "                comfort += min(abs(temp_range[0] - T), abs(T - temp_range[1]))\n",
                "  \n",
                " \n",
                "\n",
                "        return comfort, temps\n",
                "\n",
                "\n",
                "class MyExpReward(MyLinearReward):\n",
                "\n",
                "    def __init__(\n",
                "        self,\n",
                "        env: Env,\n",
                "        temperature_variable: Union[str, list],\n",
                "        energy_variable: str,\n",
                "        range_comfort_winter: Tuple[int, int],\n",
                "        range_comfort_summer: Tuple[int, int],\n",
                "        summer_start: Tuple[int, int] = (6, 1),\n",
                "        summer_final: Tuple[int, int] = (9, 30),\n",
                "        #changes from 0.5 to 0.7\n",
                "        energy_weight: float = 1,\n",
                "        lambda_energy: float = 1e-4,\n",
                "        #lambda_energy: float = 1,\n",
                "        lambda_temperature: float = 1\n",
                "    ):\n",
                "        \"\"\"\n",
                "        Reward considering exponential absolute difference to temperature comfort.\n",
                "\n",
                "        .. math::\n",
                "            R = - W * lambda_E * power - (1 - W) * lambda_T * exp( (max(T - T_{low}, 0) + max(T_{up} - T, 0)) )\n",
                "\n",
                "        Args:\n",
                "            env (Env): Gym environment.\n",
                "            temperature_variable (Union[str, list]): Name(s) of the temperature variable(s).\n",
                "            energy_variable (str): Name of the energy/power variable.\n",
                "            range_comfort_winter (Tuple[int,int]): Temperature comfort range for cold season. Depends on environment you are using.\n",
                "            range_comfort_summer (Tuple[int,int]): Temperature comfort range for hot season. Depends on environment you are using.\n",
                "            summer_start (Tuple[int,int]): Summer session tuple with month and day start. Defaults to (6,1).\n",
                "            summer_final (Tuple[int,int]): Summer session tuple with month and day end. defaults to (9,30).\n",
                "            energy_weight (float, optional): Weight given to the energy term. Defaults to 0.5.\n",
                "            lambda_energy (float, optional): Constant for removing dimensions from power(1/W). Defaults to 1e-4.\n",
                "            lambda_temperature (float, optional): Constant for removing dimensions from temperature(1/C). Defaults to 1.0.\n",
                "        \"\"\"\n",
                "\n",
                "        super(MyExpReward, self).__init__(\n",
                "            env,\n",
                "            temperature_variable,\n",
                "            energy_variable,\n",
                "            range_comfort_winter,\n",
                "            range_comfort_summer,\n",
                "            summer_start,\n",
                "            summer_final,\n",
                "            energy_weight,\n",
                "            lambda_energy,\n",
                "            lambda_temperature\n",
                "        )\n",
                "\n",
                "    def _get_comfort(self,\n",
                "                     obs_dict: Dict[str,\n",
                "                                    Any]) -> Tuple[float,\n",
                "                                                   List[float]]:\n",
                "        \"\"\"Calculate the comfort term of the reward.\n",
                "\n",
                "        Returns:\n",
                "            Tuple[float, List[float]]: comfort penalty and List with temperatures used.\n",
                "        \"\"\"\n",
                "\n",
                "        hour = obs_dict[\"hour\"]\n",
                "        month = obs_dict['month']\n",
                "        day = obs_dict['day']\n",
                "        year = obs_dict['year']\n",
                "        current_dt = datetime(year, month, day)\n",
                "\n",
                "        # Periods\n",
                "        summer_start_date = datetime(\n",
                "            year,\n",
                "            self.summer_start[0],\n",
                "            self.summer_start[1])\n",
                "        summer_final_date = datetime(\n",
                "            year,\n",
                "            self.summer_final[0],\n",
                "            self.summer_final[1])\n",
                "\n",
                "        # if current_dt >= summer_start_date and current_dt <= summer_final_date:\n",
                "        #     temp_range = self.range_comfort_summer \n",
                "        # else:\n",
                "        #     temp_range = self.range_comfort_winter\n",
                "        if current_dt >= summer_start_date and current_dt <= summer_final_date:\n",
                "            if current_dt.weekday() >= 5 or hour not in range(8,19):\n",
                "                temp_range = (15,30)\n",
                "            else:\n",
                "                temp_range = self.range_comfort_summer \n",
                "        else:\n",
                "            if current_dt.weekday() >= 5 or hour not in range(8,19):\n",
                "                temp_range = (15,30)\n",
                "            else:\n",
                "                temp_range = self.range_comfort_winter\n",
                "\n",
                "\n",
                "        temps = [v for k, v in obs_dict.items() if k in self.temp_name]\n",
                "        comfort = 0.0\n",
                "        for T in temps:\n",
                "            if T < temp_range[0] or T > temp_range[1]:\n",
                "                comfort += exp(min(abs(temp_range[0] - T),\n",
                "                                   abs(T - temp_range[1])))\n",
                "\n",
                "            # else:\n",
                "            #     comfort -= 5\n",
                "\n",
                "        return comfort, temps\n",
                "\n",
                "\n",
                "class MyHourlyExpReward(MyExpReward):\n",
                "\n",
                "    def __init__(\n",
                "        self,\n",
                "        env: Env,\n",
                "        temperature_variable: Union[str, list],\n",
                "        energy_variable: str,\n",
                "        # range_comfort_winter: Tuple[int, int],\n",
                "        # range_comfort_summer: Tuple[int, int],\n",
                "        range_comfort_winter = (20,23),\n",
                "        range_comfort_summer = (23,26),\n",
                "        summer_start: Tuple[int, int] = (6, 1),\n",
                "        summer_final: Tuple[int, int] = (9, 30),\n",
                "        min_energy_weight: float = 0.3,\n",
                "        #default energy lambda = 1\n",
                "        lambda_energy: float = 2e-4,\n",
                "        lambda_temperature: float = 2,\n",
                "        range_comfort_hours: tuple = (8, 19)\n",
                "    ):\n",
                "        \"\"\"\n",
                "        Linear reward function with a time-dependent weight for consumption and energy terms.\n",
                "\n",
                "        Args:\n",
                "            env (Env): Gym environment.\n",
                "            temperature_variable (Union[str, list]): Name(s) of the temperature variable(s).\n",
                "            energy_variable (str): Name of the energy/power variable.\n",
                "            range_comfort_winter (Tuple[int,int]): Temperature comfort range for cold season. Depends on environment you are using.\n",
                "            range_comfort_summer (Tuple[int,int]): Temperature comfort range for hot season. Depends on environment you are using.\n",
                "            summer_start (Tuple[int,int]): Summer session tuple with month and day start. Defaults to (6,1).\n",
                "            summer_final (Tuple[int,int]): Summer session tuple with month and day end. defaults to (9,30).\n",
                "            min_energy_weight (float, optional): Minimum weight given to the energy term. Defaults to 0.5.\n",
                "            lambda_energy (float, optional): Constant for removing dimensions from power(1/W). Defaults to 1e-4.\n",
                "            lambda_temperature (float, optional): Constant for removing dimensions from temperature(1/C). Defaults to 1.0.\n",
                "            range_comfort_hours (tuple, optional): Hours where thermal comfort is considered. Defaults to (9, 19).\n",
                "        \"\"\"\n",
                "\n",
                "        super(MyHourlyExpReward, self).__init__(\n",
                "            env,\n",
                "            temperature_variable,\n",
                "            energy_variable,\n",
                "            range_comfort_winter,\n",
                "            range_comfort_summer,\n",
                "            summer_start,\n",
                "            summer_final,\n",
                "            min_energy_weight,\n",
                "            lambda_energy,\n",
                "            lambda_temperature\n",
                "        )\n",
                "\n",
                "\n",
                "\n",
                "        # Reward parameters\n",
                "        self.range_comfort_hours = range_comfort_hours\n",
                "\n",
                "    def __call__(self) -> Tuple[float, Dict[str, Any]]:\n",
                "        \"\"\"Calculate the reward function.\n",
                "\n",
                "        Returns:\n",
                "            Tuple[float, Dict[str, Any]]: Reward and dict with reward terms.\n",
                "            \"\"\"\n",
                "        # Current observation\n",
                "        obs_dict = self.env.obs_dict.copy()\n",
                "\n",
                "        # Energy term\n",
                "        #reward_energy = - self.lambda_energy * obs_dict[self.energy_name]\n",
                "        reward_energy = - self.lambda_energy * obs_dict['Facility Total HVAC Electricity Demand Rate(Whole Building)']\n",
                "        # Comfort\n",
                "        comfort, temps = self._get_comfort(obs_dict)\n",
                "\n",
                "        if comfort == 0:\n",
                "            reward_comfort = 0\n",
                "        else:   \n",
                "            reward_comfort = - self.lambda_temp * comfort\n",
                "\n",
                "        # Determine energy weight depending on the hour\n",
                "        hour = obs_dict['hour']\n",
                "        if hour >= self.range_comfort_hours[0] and hour <= self.range_comfort_hours[1]:\n",
                "            weight = self.W_energy\n",
                "        else:\n",
                "            weight = 1\n",
                "\n",
                "\n",
                "        # Weighted sum of both terms\n",
                "        reward = weight * reward_energy + (1.0 - weight) * reward_comfort\n",
                "\n",
                "        reward_terms = {\n",
                "            'reward_energy': reward_energy,\n",
                "            'total_energy': obs_dict[self.energy_name],\n",
                "            'reward_comfort': reward_comfort,\n",
                "            'temperatures': temps\n",
                "        }\n",
                "\n",
                "        return reward, reward_terms\n",
                "\n",
                "class MyHourlyLinearReward(MyLinearReward):\n",
                "\n",
                "    def __init__(\n",
                "        self,\n",
                "        env: Env,\n",
                "        temperature_variable: Union[str, list],\n",
                "        energy_variable: str,\n",
                "        range_comfort_winter: Tuple[int, int],\n",
                "        range_comfort_summer: Tuple[int, int],\n",
                "        summer_start: Tuple[int, int] = (6, 1),\n",
                "        summer_final: Tuple[int, int] = (9, 30),\n",
                "        min_energy_weight: float = 0.3,\n",
                "        lambda_energy: float = 2e-4,\n",
                "        lambda_temperature: float = 2,\n",
                "        range_comfort_hours: tuple = (8, 19),\n",
                "    ):\n",
                "        \"\"\"\n",
                "        Linear reward function with a time-dependent weight for consumption and energy terms.\n",
                "\n",
                "        Args:\n",
                "            env (Env): Gym environment.\n",
                "            temperature_variable (Union[str, list]): Name(s) of the temperature variable(s).\n",
                "            energy_variable (str): Name of the energy/power variable.\n",
                "            range_comfort_winter (Tuple[int,int]): Temperature comfort range for cold season. Depends on environment you are using.\n",
                "            range_comfort_summer (Tuple[int,int]): Temperature comfort range for hot season. Depends on environment you are using.\n",
                "            summer_start (Tuple[int,int]): Summer session tuple with month and day start. Defaults to (6,1).\n",
                "            summer_final (Tuple[int,int]): Summer session tuple with month and day end. defaults to (9,30).\n",
                "            min_energy_weight (float, optional): Minimum weight given to the energy term. Defaults to 0.5.\n",
                "            lambda_energy (float, optional): Constant for removing dimensions from power(1/W). Defaults to 1e-4.\n",
                "            lambda_temperature (float, optional): Constant for removing dimensions from temperature(1/C). Defaults to 1.0.\n",
                "            range_comfort_hours (tuple, optional): Hours where thermal comfort is considered. Defaults to (9, 19).\n",
                "        \"\"\"\n",
                "\n",
                "        super(MyHourlyLinearReward, self).__init__(\n",
                "            env,\n",
                "            temperature_variable,\n",
                "            energy_variable,\n",
                "            range_comfort_winter,\n",
                "            range_comfort_summer,\n",
                "            summer_start,\n",
                "            summer_final,\n",
                "            min_energy_weight,\n",
                "            lambda_energy,\n",
                "            lambda_temperature\n",
                "        )\n",
                "\n",
                "        # Reward parameters\n",
                "        self.range_comfort_hours = range_comfort_hours\n",
                "\n",
                "    def __call__(self) -> Tuple[float, Dict[str, Any]]:\n",
                "        \"\"\"Calculate the reward function.\n",
                "\n",
                "        Returns:\n",
                "            Tuple[float, Dict[str, Any]]: Reward and dict with reward terms.\n",
                "            \"\"\"\n",
                "        # Current observation\n",
                "        obs_dict = self.env.obs_dict.copy()\n",
                "\n",
                "        # Energy term\n",
                "        reward_energy = - self.lambda_energy * obs_dict[self.energy_name]\n",
                "\n",
                "        # Comfort\n",
                "        comfort, temps = self._get_comfort(obs_dict)\n",
                "\n",
                "        if comfort == 0:\n",
                "            reward_comfort = 0\n",
                "        else:\n",
                "            reward_comfort = - self.lambda_temp * (comfort)**2\n",
                "\n",
                "        # Determine energy weight depending on the hour\n",
                "        hour = obs_dict['hour']\n",
                "        if hour >= self.range_comfort_hours[0] and hour <= self.range_comfort_hours[1]:\n",
                "            weight = self.W_energy\n",
                "        else:\n",
                "            weight = 1\n",
                "\n",
                "\n",
                "        # Weighted sum of both terms\n",
                "        reward = weight * reward_energy + (1.0 - weight) * reward_comfort\n",
                "\n",
                "        reward_terms = {\n",
                "            'reward_energy': reward_energy,\n",
                "            'total_energy': obs_dict[self.energy_name],\n",
                "            'reward_comfort': reward_comfort,\n",
                "            'temperatures': temps\n",
                "        }\n",
                "\n",
                "        return reward, reward_terms\n",
                "\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# create the environment and perform RL\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[2023-02-09 17:55:09,359] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:Updating idf ExternalInterface object if it is not present...\n",
                        "[2023-02-09 17:55:09,363] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:Updating idf Site:Location and SizingPeriod:DesignDay(s) to weather and ddy file...\n",
                        "[2023-02-09 17:55:09,389] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:Updating idf OutPut:Variable and variables XML tree model for BVCTB connection.\n",
                        "[2023-02-09 17:55:09,415] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:Setting up extra configuration in building model if exists...\n",
                        "[2023-02-09 17:55:09,417] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:Setting up action definition in building model if exists...\n",
                        "Using cpu device\n",
                        "Wrapping the env with a `Monitor` wrapper\n",
                        "Wrapping the env in a DummyVecEnv.\n",
                        "[2023-02-09 17:55:09,838] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
                        "[2023-02-09 17:55:10,745] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/examples/Eplus-env-5Zone-mixed-discrete-v1-res1/Eplus-env-sub_run1\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
                        "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
                        "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
                        "  ret = ret.dtype.type(ret / rcount)\n",
                        "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
                        "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
                        "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
                        "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
                        "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:257: RuntimeWarning: invalid value encountered in double_scalars\n",
                        "  ret = ret.dtype.type(ret / rcount)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[2023-02-09 18:02:00,597] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
                        "[2023-02-09 18:02:00,600] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
                        "[2023-02-09 18:02:00,777] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/examples/Eplus-env-5Zone-mixed-discrete-v1-res1/Eplus-env-sub_run2\n",
                        "[2023-02-09 18:09:38,028] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
                        "[2023-02-09 18:09:38,031] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
                        "[2023-02-09 18:09:38,293] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/examples/Eplus-env-5Zone-mixed-discrete-v1-res1/Eplus-env-sub_run3\n",
                        "[2023-02-09 18:10:19,129] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
                        "[2023-02-09 18:10:19,137] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
                        "[2023-02-09 18:10:19,396] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/examples/Eplus-env-5Zone-mixed-discrete-v1-res1/Eplus-env-sub_run4\n",
                        "[2023-02-09 18:17:31,908] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
                        "[2023-02-09 18:17:31,915] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
                        "[2023-02-09 18:17:32,129] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/examples/Eplus-env-5Zone-mixed-discrete-v1-res1/Eplus-env-sub_run5\n",
                        "[2023-02-09 18:26:01,079] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
                        "[2023-02-09 18:26:01,299] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
                        "[2023-02-09 18:26:01,778] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/examples/Eplus-env-5Zone-mixed-discrete-v1-res1/Eplus-env-sub_run6\n",
                        "Eval num_timesteps=70272, episode_reward=-29435.49 +/- 0.00\n",
                        "Episode length: 35136.00 +/- 0.00\n",
                        "New best mean reward!\n",
                        "[2023-02-09 18:36:19,733] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
                        "[2023-02-09 18:36:19,738] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
                        "[2023-02-09 18:36:20,054] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/examples/Eplus-env-5Zone-mixed-discrete-v1-res1/Eplus-env-sub_run7\n",
                        "[2023-02-09 18:45:39,210] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
                        "[2023-02-09 18:45:39,358] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
                        "[2023-02-09 18:45:39,708] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/examples/Eplus-env-5Zone-mixed-discrete-v1-res1/Eplus-env-sub_run8\n",
                        "[2023-02-09 18:46:28,588] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
                        "[2023-02-09 18:46:28,601] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
                        "[2023-02-09 18:46:28,794] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/examples/Eplus-env-5Zone-mixed-discrete-v1-res1/Eplus-env-sub_run9\n",
                        "[2023-02-09 18:52:28,078] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
                        "[2023-02-09 18:52:28,116] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
                        "[2023-02-09 18:52:28,401] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/examples/Eplus-env-5Zone-mixed-discrete-v1-res1/Eplus-env-sub_run10\n",
                        "[2023-02-09 18:58:33,511] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
                        "[2023-02-09 18:58:33,578] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
                        "[2023-02-09 18:58:34,115] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/examples/Eplus-env-5Zone-mixed-discrete-v1-res1/Eplus-env-sub_run11\n",
                        "Eval num_timesteps=140544, episode_reward=-22994.91 +/- 0.00\n",
                        "Episode length: 35136.00 +/- 0.00\n",
                        "New best mean reward!\n",
                        "[2023-02-09 19:12:28,530] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
                        "[2023-02-09 19:12:28,563] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
                        "[2023-02-09 19:12:29,042] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/examples/Eplus-env-5Zone-mixed-discrete-v1-res1/Eplus-env-sub_run12\n",
                        "[2023-02-09 19:21:53,306] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
                        "[2023-02-09 19:21:53,324] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
                        "[2023-02-09 19:21:53,900] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/examples/Eplus-env-5Zone-mixed-discrete-v1-res1/Eplus-env-sub_run13\n",
                        "[2023-02-09 19:22:43,951] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
                        "[2023-02-09 19:22:44,006] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
                        "[2023-02-09 19:22:44,460] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/examples/Eplus-env-5Zone-mixed-discrete-v1-res1/Eplus-env-sub_run14\n",
                        "[2023-02-09 19:28:23,269] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
                        "[2023-02-09 19:28:23,297] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
                        "[2023-02-09 19:28:24,269] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/examples/Eplus-env-5Zone-mixed-discrete-v1-res1/Eplus-env-sub_run15\n",
                        "[2023-02-09 19:39:50,513] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
                        "[2023-02-09 19:39:50,668] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
                        "[2023-02-09 19:39:51,836] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/examples/Eplus-env-5Zone-mixed-discrete-v1-res1/Eplus-env-sub_run16\n",
                        "Eval num_timesteps=210816, episode_reward=-23424.51 +/- 0.00\n",
                        "Episode length: 35136.00 +/- 0.00\n",
                        "[2023-02-09 19:56:53,214] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
                        "[2023-02-09 19:56:53,278] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
                        "[2023-02-09 19:56:54,760] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/examples/Eplus-env-5Zone-mixed-discrete-v1-res1/Eplus-env-sub_run17\n",
                        "[2023-02-09 20:06:21,819] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
                        "[2023-02-09 20:06:21,842] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
                        "[2023-02-09 20:06:22,164] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/examples/Eplus-env-5Zone-mixed-discrete-v1-res1/Eplus-env-sub_run18\n",
                        "[2023-02-09 20:07:06,619] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
                        "[2023-02-09 20:07:06,640] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
                        "[2023-02-09 20:07:07,032] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/examples/Eplus-env-5Zone-mixed-discrete-v1-res1/Eplus-env-sub_run19\n",
                        "[2023-02-09 20:12:48,898] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
                        "[2023-02-09 20:12:48,927] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
                        "[2023-02-09 20:12:49,379] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/examples/Eplus-env-5Zone-mixed-discrete-v1-res1/Eplus-env-sub_run20\n",
                        "[2023-02-09 20:18:49,554] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
                        "[2023-02-09 20:18:49,618] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
                        "[2023-02-09 20:18:50,354] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/examples/Eplus-env-5Zone-mixed-discrete-v1-res1/Eplus-env-sub_run21\n",
                        "Eval num_timesteps=281088, episode_reward=-19212.56 +/- 0.00\n",
                        "Episode length: 35136.00 +/- 0.00\n",
                        "New best mean reward!\n",
                        "[2023-02-09 20:26:44,477] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
                        "[2023-02-09 20:26:44,485] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
                        "[2023-02-09 20:26:44,733] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/examples/Eplus-env-5Zone-mixed-discrete-v1-res1/Eplus-env-sub_run22\n",
                        "[2023-02-09 20:34:17,099] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
                        "[2023-02-09 20:34:17,131] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
                        "[2023-02-09 20:34:17,340] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/examples/Eplus-env-5Zone-mixed-discrete-v1-res1/Eplus-env-sub_run23\n",
                        "[2023-02-09 20:34:43,801] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
                        "[2023-02-09 20:34:43,822] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
                        "[2023-02-09 20:34:44,159] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/examples/Eplus-env-5Zone-mixed-discrete-v1-res1/Eplus-env-sub_run24\n",
                        "[2023-02-09 20:39:15,436] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
                        "[2023-02-09 20:39:15,446] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
                        "[2023-02-09 20:39:15,697] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/examples/Eplus-env-5Zone-mixed-discrete-v1-res1/Eplus-env-sub_run25\n",
                        "[2023-02-09 20:43:48,636] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
                        "[2023-02-09 20:43:48,657] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
                        "[2023-02-09 20:43:49,188] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/examples/Eplus-env-5Zone-mixed-discrete-v1-res1/Eplus-env-sub_run26\n",
                        "Eval num_timesteps=351360, episode_reward=-20320.62 +/- 0.00\n",
                        "Episode length: 35136.00 +/- 0.00\n",
                        "[2023-02-09 20:44:10,035] EPLUS_ENV_5Zone-mixed-discrete-v1_MainThread_ROOT INFO:EnergyPlus simulation closed successfully. \n"
                    ]
                }
            ],
            "source": [
                "#environment = \"Eplus-demo-v1\"\n",
                "environment  = \"Eplus-5Zone-mixed-discrete-v1\"\n",
                "#environment = \"Eplus-5Zone-mixed- continuous-v1\"\n",
                "weather = \"ESP_Granada.084190_SWEC.epw\"\n",
                "\n",
                "\n",
                "\n",
                "episodes = 10\n",
                "experiment_date = datetime.today().strftime('%Y-%m-%d %H:%M')\n",
                "\n",
                "#choose the simulation period\n",
                "begin_day = 1\n",
                "begin_month = 1\n",
                "begin_year = 2021\n",
                "end_day = 1\n",
                "end_month = 1\n",
                "end_year = 2022\n",
                "\n",
                "# register run name\n",
                "name = F\"{environment}-episodes_{episodes}({experiment_date})\"\n",
                "\n",
                "\n",
                "# Set to one month only to reduce running time\n",
                "extra_params={'timesteps_per_hour' : 4,\n",
                "              'runperiod' : (begin_day,begin_month,begin_year,end_day,end_month,end_year)}\n",
                "\n",
                "new_observation_variables=[\n",
                "    'Site Outdoor Air Drybulb Temperature(Environment)',\n",
                "    'Site Diffuse Solar Radiation Rate per Area(Environment)',\n",
                "    'Zone Thermostat Heating Setpoint Temperature(SPACE1-1)',\n",
                "    'Zone Thermostat Cooling Setpoint Temperature(SPACE1-1)',\n",
                "     'Zone Air Temperature(SPACE1-1)',\n",
                "    # 'Zone People Occupant Count(SPACE1-1)',\n",
                "    # 'People Air Temperature(SPACE1-1 PEOPLE 1)',\n",
                "    'Facility Total HVAC Electricity Demand Rate(Whole Building)']\n",
                "\n",
                "new_observation_space = gym.spaces.Box(\n",
                "    low=-5e6,\n",
                "    high=5e6,\n",
                "    shape=(len(new_observation_variables) + 4,),\n",
                "    dtype=np.float32)\n",
                "\n",
                "\n",
                "new_action_variables = [\n",
                "    'Heating_Setpoint_RL',\n",
                "    'Cooling_Setpoint_RL',\n",
                "]\n",
                "\n",
                "new_action_mapping = {\n",
                "    0: (15, 30),\n",
                "    1: (16, 29),\n",
                "    2: (17, 28),\n",
                "    3: (18, 27),\n",
                "    4: (19, 26),\n",
                "    5: (20, 25),\n",
                "    6: (21, 24),\n",
                "    7: (22, 23),\n",
                "    8: (22, 22),\n",
                "    9: (21, 21)\n",
                "}\n",
                "\n",
                "new_action_space = gym.spaces.Discrete(10)\n",
                "\n",
                "env = gym.make(environment, \n",
                "                weather_file = weather,\n",
                "                reward = MyHourlyExpReward, \n",
                "                config_params = extra_params,\n",
                "                observation_variables = new_observation_variables,\n",
                "                observation_space = new_observation_space,\n",
                "                action_variables=new_action_variables,\n",
                "                action_mapping=new_action_mapping,\n",
                "                action_space=new_action_space\n",
                "                )\n",
                "\n",
                "\n",
                "\n",
                "env = LoggerWrapper(NormalizeObservation(env, ranges = RANGES_5ZONE))\n",
                "\n",
                "model = DQN('MlpPolicy', env, verbose=1,\n",
                "    batch_size=5000,\n",
                "    learning_rate=0.001)\n",
                "\n",
                "\n",
                "\n",
                "n_timesteps_episode = env.simulator._eplus_one_epi_len / env.simulator._eplus_run_stepsize\n",
                "\n",
                "env_vec = DummyVecEnv([lambda: env])\n",
                "\n",
                "callbacks = []\n",
                "\n",
                "# Set up Evaluation and saving best model\n",
                "eval_callback = LoggerEvalCallback(\n",
                "    env_vec,\n",
                "    best_model_save_path='best_model/' + name + '/',\n",
                "    log_path='best_model/' + name + '/',\n",
                "    eval_freq=n_timesteps_episode * 2,\n",
                "    deterministic=True,\n",
                "    render=False,\n",
                "    n_eval_episodes=2)\n",
                "callbacks.append(eval_callback)\n",
                "\n",
                "callback = CallbackList(callbacks)\n",
                "\n",
                "timesteps = episodes * n_timesteps_episode\n",
                "\n",
                "model.learn(\n",
                "    total_timesteps=timesteps,\n",
                "    callback=callback,\n",
                "    log_interval=100)\n",
                "\n",
                "#model.save(env.simulator._env_working_dir_parent + '/' + name)\n",
                "\n",
                "env.close()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.10.6 64-bit",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.6"
        },
        "vscode": {
            "interpreter": {
                "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
